{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a55fcc-5ca9-430f-ae85-5692e8358d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing data processing.\n",
    "import pandas as pd\n",
    "import os\n",
    "def prepare_sales_data(file_path):\n",
    "    # Load the sales data\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df,id_vars=['Product Code', 'Product Name'], var_name='Date', value_name='Sales')\n",
    "    # Example data preparation steps\n",
    "    # Convert date columns to periods\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "    # Potentially other preprocessing like filling missing values, etc.\n",
    "    # df = ...\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8dd4ff-695d-44db-93e7-60d9f59f8dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product Code       Product Name       Date  Sales\n",
      "0            FG001    Finished Good A 2023-01-01      0\n",
      "1            FG002    Finished Good B 2023-01-01      0\n",
      "2            FG003    Finished Good C 2023-01-01      5\n",
      "3            FG004    Finished Good D 2023-01-01      2\n",
      "4            FG005    Finished Good E 2023-01-01      0\n",
      "...            ...                ...        ...    ...\n",
      "16957        FG029   Finished Good D1 2024-05-28     11\n",
      "16958        FG030   Finished Good F1 2024-05-28     11\n",
      "16959        FG031  Finished Good LG1 2024-05-28      0\n",
      "16960        FG032   Finished Good H1 2024-05-28     28\n",
      "16961        FG033   Finished Good J1 2024-05-28      0\n",
      "\n",
      "[16962 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(\"data\", \"sales_data.csv\")\n",
    "df = prepare_sales_data(file_path) \n",
    "print(df)\n",
    " \n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec76a48-0598-46ed-8961-a58f5a4e6ecd",
   "metadata": {},
   "source": [
    "# Function to create date and period features\n",
    "def period_features(melted_sales_data):\n",
    "    # Add New Date features\n",
    "    melted_sales_data['weekday'] = melted_sales_data['Date'].dt.weekday\n",
    "    melted_sales_data['month'] = melted_sales_data['Date'].dt.month\n",
    "    melted_sales_data['year'] = melted_sales_data['Date'].dt.year\n",
    "    melted_sales_data['dayofyear'] = melted_sales_data['Date'].dt.dayofyear\n",
    "    melted_sales_data['weekofyear'] = melted_sales_data['Date'].dt.isocalendar().week\n",
    "    melted_sales_data['quarter'] = melted_sales_data['Date'].dt.quarter\n",
    "\n",
    "    # Rolling window features\n",
    "    melted_sales_data['rolling_mean_7'] = melted_sales_data.groupby(['Product Code', 'Product Name'])['Sales'].shift(1).rolling(window=7).mean()\n",
    "    melted_sales_data['rolling_std_7'] = melted_sales_data.groupby(['Product Code', 'Product Name'])['Sales'].shift(1).rolling(window=7).std()\n",
    "    melted_sales_data['rolling_mean_30'] = melted_sales_data.groupby(['Product Code', 'Product Name'])['Sales'].shift(1).rolling(window=30).mean()\n",
    "    melted_sales_data['rolling_std_30'] = melted_sales_data.groupby(['Product Code', 'Product Name'])['Sales'].shift(1).rolling(window=30).std()\n",
    "\n",
    "    return melted_sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e52408-3e63-48ae-b536-2980259001c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE across all products: 10.52620142078916\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def holt_winters_cross_validation(sales_data, n_splits=5):\n",
    "    sales_data = os.path.join(\"data\", \"sales_data.csv\")\n",
    "    df = prepare_sales_data(sales_data)    \n",
    "    product_codes = df['Product Code'].unique()\n",
    "    product_names = df['Product Name'].unique()\n",
    "\n",
    "    all_errors = []\n",
    "\n",
    "    for product_code, product_name in zip(product_codes, product_names):\n",
    "        # Filter the data for the specific product\n",
    "        product_data = df.loc[(df['Product Code'] == product_code) & \n",
    "                                             (df['Product Name'] == product_name)].copy()\n",
    "        \n",
    "        # Set 'Date' as the index and convert to PeriodIndex with daily frequency\n",
    "        product_data['Date'] = pd.to_datetime(product_data['Date'])  # Ensure it's datetime first\n",
    "        product_data.set_index('Date', inplace=True)\n",
    "        product_data.index = product_data.index.to_period('D')  # Convert the index to PeriodIndex\n",
    "\n",
    "        # Split the data into train and test\n",
    "        total_points = len(product_data)\n",
    "        split_size = total_points // n_splits\n",
    "        \n",
    "        product_errors = []\n",
    "        \n",
    "        for i in range(n_splits):\n",
    "            train_end = (i + 1) * split_size\n",
    "            train_data = product_data.iloc[:train_end]\n",
    "            test_data = product_data.iloc[train_end:train_end + split_size]\n",
    "            \n",
    "            if len(test_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Fit the Holt-Winters model\n",
    "            model = ExponentialSmoothing(train_data['Sales'], trend='add', seasonal='add', seasonal_periods=12).fit()\n",
    "            \n",
    "            # Predict the next values\n",
    "            forecast = model.forecast(len(test_data))\n",
    "            \n",
    "            # Calculate RMSE for this split\n",
    "            rmse = sqrt(mean_squared_error(test_data['Sales'], forecast))\n",
    "            product_errors.append(rmse)\n",
    "        \n",
    "        # Calculate the average RMSE for this product and add to the list\n",
    "        avg_product_rmse = np.mean(product_errors)\n",
    "        all_errors.append(avg_product_rmse)\n",
    "    \n",
    "    # Calculate the average RMSE across all products\n",
    "    overall_avg_rmse = np.mean(all_errors)\n",
    "    return overall_avg_rmse\n",
    "\n",
    "# Example usage:\n",
    "average_rmse = holt_winters_cross_validation(df)\n",
    "print(\"Average RMSE across all products:\", average_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a685b9a-1797-4c78-9a81-8ca09a31b921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product Code       Product Name  2024-05-29  2024-05-30  2024-05-31  \\\n",
      "0         FG001    Finished Good A         4.0         5.0         6.0   \n",
      "1         FG002    Finished Good B         4.0         5.0         7.0   \n",
      "2         FG003    Finished Good C        10.0        12.0        10.0   \n",
      "3         FG004    Finished Good D         2.0         2.0         2.0   \n",
      "4         FG005    Finished Good E         3.0         2.0         3.0   \n",
      "5         FG006    Finished Good F         8.0         9.0         9.0   \n",
      "6         FG007    Finished Good G         6.0         5.0         5.0   \n",
      "7         FG008    Finished Good H         7.0         7.0         8.0   \n",
      "8         FG009    Finished Good I        14.0        14.0        17.0   \n",
      "9         FG010    Finished Good J        37.0        39.0        36.0   \n",
      "10        FG011    Finished Good K        25.0        25.0        24.0   \n",
      "11        FG012    Finished Good L        45.0        46.0        46.0   \n",
      "12        FG013    Finished Good M        22.0        26.0        24.0   \n",
      "13        FG014    Finished Good N        27.0        29.0        28.0   \n",
      "14        FG015    Finished Good O        16.0        17.0        18.0   \n",
      "15        FG016    Finished Good P        14.0        15.0        15.0   \n",
      "16        FG017    Finished Good Q        18.0        15.0        19.0   \n",
      "17        FG018    Finished Good R        11.0        11.0        11.0   \n",
      "18        FG019    Finished Good S        29.0        29.0        30.0   \n",
      "19        FG020    Finished Good T         4.0         5.0         3.0   \n",
      "20        FG021    Finished Good U        32.0        34.0        35.0   \n",
      "21        FG022    Finished Good V        26.0        25.0        27.0   \n",
      "22        FG023    Finished Good W         9.0        10.0        10.0   \n",
      "23        FG024    Finished Good X        54.0        52.0        56.0   \n",
      "24        FG025    Finished Good Z        45.0        46.0        47.0   \n",
      "25        FG026   Finished Good A1        22.0        22.0        21.0   \n",
      "26        FG027   Finished Good B1         7.0         6.0         6.0   \n",
      "27        FG028   Finished Good C1        10.0        11.0        11.0   \n",
      "28        FG029   Finished Good D1        11.0        11.0        12.0   \n",
      "29        FG030   Finished Good F1         7.0         6.0         7.0   \n",
      "30        FG031  Finished Good LG1         0.0         0.0         0.0   \n",
      "31        FG032   Finished Good H1        21.0        23.0        23.0   \n",
      "32        FG033   Finished Good J1         0.0         1.0         2.0   \n",
      "\n",
      "    2024-06-01  2024-06-02  2024-06-03  2024-06-04  2024-06-05  ...  \\\n",
      "0          9.0         5.0         6.0         7.0         8.0  ...   \n",
      "1          4.0         5.0         4.0         5.0         7.0  ...   \n",
      "2         11.0        11.0        11.0        12.0        13.0  ...   \n",
      "3          2.0         3.0         2.0         2.0         2.0  ...   \n",
      "4          3.0         4.0         3.0         3.0         2.0  ...   \n",
      "5          8.0         8.0         9.0         9.0         9.0  ...   \n",
      "6          5.0         6.0         5.0         5.0         6.0  ...   \n",
      "7          8.0         8.0         8.0         8.0         7.0  ...   \n",
      "8         16.0        16.0        13.0        15.0        16.0  ...   \n",
      "9         40.0        36.0        38.0        40.0        36.0  ...   \n",
      "10        22.0        24.0        23.0        22.0        23.0  ...   \n",
      "11        45.0        44.0        45.0        47.0        44.0  ...   \n",
      "12        25.0        27.0        23.0        25.0        23.0  ...   \n",
      "13        29.0        25.0        27.0        28.0        26.0  ...   \n",
      "14        17.0        16.0        17.0        19.0        18.0  ...   \n",
      "15        15.0        15.0        13.0        14.0        14.0  ...   \n",
      "16        21.0        14.0        17.0        17.0        16.0  ...   \n",
      "17        10.0        10.0        10.0        12.0        10.0  ...   \n",
      "18        29.0        29.0        29.0        30.0        27.0  ...   \n",
      "19         3.0         3.0         1.0         3.0         6.0  ...   \n",
      "20        34.0        34.0        35.0        33.0        31.0  ...   \n",
      "21        25.0        23.0        24.0        24.0        25.0  ...   \n",
      "22         9.0         9.0         9.0         9.0        10.0  ...   \n",
      "23        53.0        57.0        55.0        57.0        47.0  ...   \n",
      "24        47.0        46.0        46.0        48.0        46.0  ...   \n",
      "25        23.0        23.0        24.0        22.0        22.0  ...   \n",
      "26         6.0         5.0         6.0         6.0         5.0  ...   \n",
      "27        11.0        11.0        10.0        10.0         9.0  ...   \n",
      "28        11.0        14.0        12.0        11.0        13.0  ...   \n",
      "29         6.0         7.0         6.0         7.0         6.0  ...   \n",
      "30         0.0         0.0         0.0         0.0         7.0  ...   \n",
      "31        23.0        22.0        20.0        22.0        22.0  ...   \n",
      "32        -0.0         0.0         0.0         1.0         2.0  ...   \n",
      "\n",
      "    2025-05-19  2025-05-20  2025-05-21  2025-05-22  2025-05-23  2025-05-24  \\\n",
      "0         12.0        12.0         9.0         9.0        12.0         8.0   \n",
      "1          4.0         1.0         2.0         5.0         3.0         1.0   \n",
      "2         15.0        11.0        13.0        16.0        15.0        12.0   \n",
      "3          3.0         3.0         2.0         3.0         3.0         3.0   \n",
      "4          3.0         4.0         4.0         3.0         4.0         4.0   \n",
      "5         15.0        15.0        14.0        14.0        14.0        14.0   \n",
      "6          9.0         9.0         9.0         9.0         9.0         9.0   \n",
      "7         12.0        14.0        13.0        13.0        14.0        12.0   \n",
      "8         22.0        20.0        20.0        20.0        22.0        21.0   \n",
      "9         44.0        47.0        44.0        44.0        47.0        46.0   \n",
      "10        31.0        29.0        33.0        31.0        30.0        33.0   \n",
      "11        41.0        39.0        42.0        43.0        42.0        43.0   \n",
      "12        25.0        23.0        27.0        26.0        28.0        24.0   \n",
      "13        45.0        45.0        48.0        46.0        43.0        46.0   \n",
      "14        29.0        27.0        27.0        26.0        26.0        27.0   \n",
      "15        21.0        22.0        19.0        20.0        20.0        21.0   \n",
      "16        16.0        19.0        18.0        14.0        17.0        17.0   \n",
      "17        11.0        12.0        11.0        12.0        12.0        12.0   \n",
      "18        34.0        35.0        36.0        37.0        35.0        37.0   \n",
      "19         5.0         1.0         2.0         2.0         2.0         3.0   \n",
      "20        29.0        31.0        34.0        32.0        30.0        31.0   \n",
      "21        24.0        23.0        26.0        24.0        25.0        25.0   \n",
      "22         9.0         9.0         9.0         9.0         9.0         9.0   \n",
      "23        76.0        77.0        83.0        82.0        81.0        84.0   \n",
      "24        47.0        46.0        48.0        46.0        45.0        47.0   \n",
      "25        25.0        25.0        25.0        24.0        26.0        25.0   \n",
      "26         6.0         6.0         6.0         7.0         7.0         7.0   \n",
      "27        12.0        13.0        14.0        14.0        14.0        14.0   \n",
      "28        11.0        10.0        11.0        10.0        10.0         9.0   \n",
      "29         2.0         2.0         3.0         3.0         3.0         3.0   \n",
      "30         7.0         0.0         1.0         1.0         0.0         0.0   \n",
      "31        33.0        33.0        33.0        33.0        33.0        32.0   \n",
      "32         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "    2025-05-25  2025-05-26  2025-05-27  2025-05-28  \n",
      "0          9.0        10.0        13.0         9.0  \n",
      "1          2.0         5.0         1.0         2.0  \n",
      "2         14.0        13.0        14.0        13.0  \n",
      "3          3.0         3.0         2.0         3.0  \n",
      "4          3.0         4.0         4.0         4.0  \n",
      "5         15.0        15.0        14.0        14.0  \n",
      "6          9.0         9.0         9.0         9.0  \n",
      "7         13.0        14.0        13.0        13.0  \n",
      "8         21.0        24.0        23.0        23.0  \n",
      "9         48.0        45.0        49.0        45.0  \n",
      "10        33.0        32.0        30.0        32.0  \n",
      "11        43.0        43.0        42.0        41.0  \n",
      "12        27.0        26.0        26.0        28.0  \n",
      "13        48.0        47.0        48.0        44.0  \n",
      "14        28.0        29.0        28.0        27.0  \n",
      "15        22.0        22.0        23.0        22.0  \n",
      "16        14.0        19.0        20.0        13.0  \n",
      "17        12.0        12.0        11.0        11.0  \n",
      "18        36.0        38.0        36.0        36.0  \n",
      "19         4.0         2.0         2.0         1.0  \n",
      "20        32.0        34.0        32.0        32.0  \n",
      "21        25.0        26.0        24.0        23.0  \n",
      "22         9.0        10.0         8.0         9.0  \n",
      "23        82.0        85.0        83.0        86.0  \n",
      "24        48.0        49.0        49.0        48.0  \n",
      "25        25.0        23.0        25.0        25.0  \n",
      "26         7.0         7.0         6.0         5.0  \n",
      "27        14.0        14.0        14.0        14.0  \n",
      "28        10.0        10.0        10.0        12.0  \n",
      "29         3.0         4.0         2.0         3.0  \n",
      "30         0.0         0.0         0.0         0.0  \n",
      "31        35.0        35.0        34.0        33.0  \n",
      "32         0.0         0.0         0.0         0.0  \n",
      "\n",
      "[33 rows x 367 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "def generate_forecast_for_products(sales_data, forecast_days=365):\n",
    "    sales_data = os.path.join(\"data\", \"sales_data.csv\")\n",
    "    df = prepare_sales_data(sales_data)\n",
    "    product_codes = df['Product Code'].unique()\n",
    "    product_names = df['Product Name'].unique()\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    for product_code, product_name in zip(product_codes, product_names):\n",
    "        # Filter the data for the specific product\n",
    "        product_data = df.loc[(df['Product Code'] == product_code) & \n",
    "                                             (df['Product Name'] == product_name)].copy()\n",
    "        \n",
    "        # Set 'Date' as the index and convert to PeriodIndex with daily frequency\n",
    "        product_data['Date'] = pd.to_datetime(product_data['Date'])  # Ensure it's datetime first\n",
    "        product_data.set_index('Date', inplace=True)\n",
    "        product_data.index = product_data.index.to_period('D')  # Convert the index to PeriodIndex\n",
    "\n",
    "        # Fit the Holt-Winters model\n",
    "        model = ExponentialSmoothing(product_data['Sales'], trend='add', seasonal='add', seasonal_periods=12).fit()\n",
    "        \n",
    "        # Forecast the next `forecast_days` days\n",
    "        forecast = model.forecast(forecast_days)\n",
    "        \n",
    "        # Round the forecasted values and replace any values less than zero with zero\n",
    "        forecast = forecast.round(0).clip(lower=0)  \n",
    "        \n",
    "        # Store the forecast in a list of dictionaries\n",
    "        forecast_dict = {\n",
    "            'Product Code': product_code,\n",
    "            'Product Name': product_name,\n",
    "        }\n",
    "        \n",
    "        # Add the forecasted values to the dictionary with dates as keys\n",
    "        for i, value in enumerate(forecast):\n",
    "            forecast_date = (product_data.index[-1] + pd.Timedelta(days=i+1)).strftime('%Y-%m-%d')\n",
    "            forecast_dict[forecast_date] = value\n",
    "        \n",
    "        forecasts.append(forecast_dict)\n",
    "    \n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecasts)\n",
    "    \n",
    "    return forecast_df\n",
    "\n",
    "# Example usage:\n",
    "forecasts_df = generate_forecast_for_products(df)\n",
    "print(forecasts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1026c-9afa-4c95-bcbf-31df785e314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbc351-61e4-4915-a433-1611b4b6cbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
