{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a55fcc-5ca9-430f-ae85-5692e8358d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing data processing.\n",
    "\"\"\" \n",
    "\n",
    "In this section we are centralizing testing code before deployment by testing and decoding the various steps.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "def prepare_sales_data(file_path):\n",
    "    # Load the sales data\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = pd.melt(df,id_vars=['Product Code', 'Product Name'], var_name='Date', value_name='Sales')\n",
    "    # Example data preparation steps\n",
    "    # Convert date columns to periods\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "    # Potentially other preprocessing like filling missing values, etc.\n",
    "    # df = ...\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8dd4ff-695d-44db-93e7-60d9f59f8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=prepare_sales_data(os.path.join(\"data\", \"sales_data.csv\"))\n",
    "# Date features\n",
    "df['weekday'] = pd.to_datetime(df['Date']).dt.weekday\n",
    "df['month'] = pd.to_datetime(df['Date']).dt.month\n",
    "df['year'] = pd.to_datetime(df['Date']).dt.year\n",
    "df['dayofyear'] = pd.to_datetime(df['Date']).dt.dayofyear\n",
    "df['weekofyear'] = pd.to_datetime(df['Date']).dt.isocalendar().week\n",
    "\n",
    "# Rolling window features Fill NaNs in rolling features with the overall mean and std (assuming that initial periods can use overall stats)\n",
    "df['rolling_mean_7'] = df.groupby(['Product Code','Product Name'])['Sales'].shift(1).rolling(window=7).mean().fillna(df['Sales'].mean())\n",
    "df['rolling_mean_30'] = df.groupby(['Product Code','Product Name'])['Sales'].shift(1).rolling(window=30).mean().fillna(df['Sales'].mean())\n",
    "df['rolling_std_7'] = df.groupby(['Product Code','Product Name'])['Sales'].shift(1).rolling(window=7).std().fillna(df['Sales'].mean())\n",
    "df['rolling_std_30'] = df.groupby(['Product Code','Product Name'])['Sales'].shift(1).rolling(window=30).std().fillna(df['Sales'].mean())\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5dbc351-61e4-4915-a433-1611b4b6cbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weekday  month  year  dayofyear  weekofyear  rolling_mean_7  \\\n",
      "0        6      1  2023          1          52         15.2528   \n",
      "1        6      1  2023          1          52         15.2528   \n",
      "2        6      1  2023          1          52         15.2528   \n",
      "3        6      1  2023          1          52         15.2528   \n",
      "4        6      1  2023          1          52         15.2528   \n",
      "\n",
      "   rolling_mean_30  rolling_std_7  rolling_std_30  \n",
      "0          15.2528        15.2528         15.2528  \n",
      "1          15.2528        15.2528         15.2528  \n",
      "2          15.2528        15.2528         15.2528  \n",
      "3          15.2528        15.2528         15.2528  \n",
      "4          15.2528        15.2528         15.2528  \n",
      "0    0\n",
      "1    0\n",
      "2    5\n",
      "3    2\n",
      "4    0\n",
      "Name: Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the features and target\n",
    "features = ['weekday', 'month', 'year', 'dayofyear', 'weekofyear', 'rolling_mean_7', 'rolling_mean_30',\n",
    "            'rolling_std_7', 'rolling_std_30']\n",
    "target = 'Sales'\n",
    "\n",
    "# Split features and target\n",
    "X_product = df[features]\n",
    "y_product = df[target]\n",
    "\n",
    "# Display the first few rows of features and target\n",
    "print(X_product.head())\n",
    "print(y_product.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653434d1-d399-49bf-9e54-5294b3413f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    weekday     month      year  dayofyear  weekofyear  rolling_mean_7  \\\n",
      "0 -0.502924 -0.725227  1.559396  -0.817928   -0.807999       -0.395664   \n",
      "1 -1.001913  0.447006 -0.641274   0.325527    0.335992       -1.245198   \n",
      "2  1.493032  1.033123 -0.641274   0.911668    0.874341       -0.829099   \n",
      "3  0.495054  0.153948 -0.641274   0.287092    0.268698       -0.413001   \n",
      "4 -1.500902  0.153948 -0.641274   0.046870    0.066818        0.349845   \n",
      "\n",
      "   rolling_mean_30  rolling_std_7  rolling_std_30  \n",
      "0         1.727924       0.186625        0.754991  \n",
      "1        -0.849904      -1.123902       -0.692279  \n",
      "2        -0.909655      -0.001049       -0.607692  \n",
      "3        -0.474327      -0.640184       -0.718926  \n",
      "4        -0.499934      -0.037420       -0.415720  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_product, y_product, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Display the first few rows of the scaled training data\n",
    "print(pd.DataFrame(X_train_scaled, columns=features).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603f169f-2136-4e82-9b3c-e8abfa482138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X_train_scaled after filling: 0\n",
      "NaNs in X_val_scaled after filling: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fill NaNs in X_train_scaled with the mean of the respective columns\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=features)\n",
    "X_train_scaled.fillna(X_train_scaled.mean(), inplace=True)\n",
    "\n",
    "# Fill NaNs in X_val_scaled with the mean of the respective columns\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=features)\n",
    "X_val_scaled.fillna(X_val_scaled.mean(), inplace=True)\n",
    "\n",
    "# Convert back to numpy arrays\n",
    "X_train_scaled = X_train_scaled.values\n",
    "X_val_scaled = X_val_scaled.values\n",
    "\n",
    "# Check for NaNs again\n",
    "print(\"NaNs in X_train_scaled after filling:\", np.isnan(X_train_scaled).sum())\n",
    "print(\"NaNs in X_val_scaled after filling:\", np.isnan(X_val_scaled).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d19bf-7639-4f63-b26f-355f7735e963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
